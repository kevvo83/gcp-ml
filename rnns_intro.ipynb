{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00c4b61f-69af-49ae-aebd-4075661ab0d4",
   "metadata": {},
   "source": [
    "# Intro to Recurrent Neural Nets (RNNs)\n",
    "\n",
    "Reference: https://victorzhou.com/blog/intro-to-rnns/\n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. Create Virtual Environment: `python3 -m venv datascience-venv`\n",
    "2. Set Virtual Environment: `source datascience-venv/bin/activate`\n",
    "3. Install JupyterLab in your Virtual Env using pip: `pip3 install jupyterlab`\n",
    "4. Install dependencies (`numpy`, `pandas`, `scikit-learn`) into the virtual environment\n",
    "   * `pip3 install pandas`, `pip3 install scikit-learn`\n",
    "5. Add your Virtual Environment as a kernel to Jupyterlab: `python3 -m ipykernel install --user --name=datascience-venv`\n",
    "6. Start JupyterLab from the virtual environment: `jupyter-lab --notebook-dir <location of your notebooks>`\n",
    "7. Make sure your set your Virtual Env's kernel in the notebook that you're using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37a8bb9a-fbcb-4ce1-98e2-4c3d6aff02e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from test_data.rnns_testdata import train_data, test_data\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2406dffa-f000-465d-a986-9085bdb590ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce all training data into set of unique words\n",
    "# Note: the lambda does x + y - as [1,2,3] + [4,5,6] appends 2 lists together\n",
    "vocabulary = list(set(reduce(\n",
    "    lambda list_elem1, list_elem2: list_elem1+list_elem2,\n",
    "    [key.split(' ') for key in train_data.keys()], \n",
    "    []\n",
    ")))\n",
    "assert len(vocabulary) == 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6d36c5d9-836d-4739-b3dd-3b492f9b32f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'good': True,\n",
       " 'bad': False,\n",
       " 'happy': True,\n",
       " 'sad': False,\n",
       " 'not good': False,\n",
       " 'not bad': True,\n",
       " 'not happy': False,\n",
       " 'not sad': True,\n",
       " 'very good': True,\n",
       " 'very bad': False,\n",
       " 'very happy': True,\n",
       " 'very sad': False,\n",
       " 'i am happy': True,\n",
       " 'this is good': True,\n",
       " 'i am bad': False,\n",
       " 'this is bad': False,\n",
       " 'i am sad': False,\n",
       " 'this is sad': False,\n",
       " 'i am not happy': False,\n",
       " 'this is not good': False,\n",
       " 'i am not bad': True,\n",
       " 'this is not sad': True,\n",
       " 'i am very happy': True,\n",
       " 'this is very good': True,\n",
       " 'i am very bad': False,\n",
       " 'this is very sad': False,\n",
       " 'this is very happy': True,\n",
       " 'i am good not bad': True,\n",
       " 'this is good not bad': True,\n",
       " 'i am bad not good': False,\n",
       " 'i am good and happy': True,\n",
       " 'this is not good and not happy': False,\n",
       " 'i am not at all good': False,\n",
       " 'i am not at all bad': True,\n",
       " 'i am not at all happy': False,\n",
       " 'this is not at all sad': True,\n",
       " 'this is not at all happy': False,\n",
       " 'i am good right now': True,\n",
       " 'i am bad right now': False,\n",
       " 'this is bad right now': False,\n",
       " 'i am sad right now': False,\n",
       " 'i was good earlier': True,\n",
       " 'i was happy earlier': True,\n",
       " 'i was bad earlier': False,\n",
       " 'i was sad earlier': False,\n",
       " 'i am very bad right now': False,\n",
       " 'this is very good right now': True,\n",
       " 'this is very sad right now': False,\n",
       " 'this was bad earlier': False,\n",
       " 'this was very good earlier': True,\n",
       " 'this was very bad earlier': False,\n",
       " 'this was very happy earlier': True,\n",
       " 'this was very sad earlier': False,\n",
       " 'i was good and not bad earlier': True,\n",
       " 'i was not good and not happy earlier': False,\n",
       " 'i am not at all bad or sad right now': True,\n",
       " 'i am not at all good or happy right now': False,\n",
       " 'this was not happy and not good earlier': False}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e2822ab-b2dc-46a5-868b-458873212cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bad': 0,\n",
       " 'i': 1,\n",
       " 'sad': 2,\n",
       " 'earlier': 3,\n",
       " 'all': 4,\n",
       " 'right': 5,\n",
       " 'happy': 6,\n",
       " 'good': 7,\n",
       " 'is': 8,\n",
       " 'this': 9,\n",
       " 'very': 10,\n",
       " 'and': 11,\n",
       " 'now': 12,\n",
       " 'or': 13,\n",
       " 'am': 14,\n",
       " 'was': 15,\n",
       " 'not': 16,\n",
       " 'at': 17}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_vocab_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c49e3b34-e7e9-4953-9872-ba424253d006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a map of idx to word in the vocab\n",
    "map_idx_to_vocab = {x[0]: x[1] for x in list(enumerate(vocabulary))}\n",
    "\n",
    "# Build a map of word in the vocab to idx\n",
    "map_vocab_to_idx = {x[1]: x[0] for x in list(enumerate(vocabulary))}\n",
    "\n",
    "# Create one-hot encodings for these 18 features based on the input training data\n",
    "feature_matrix = np.zeros(shape=(len(train_data), len(vocabulary)))\n",
    "assert feature_matrix.shape == (58, 18)\n",
    "\n",
    "train_data_l = list(train_data.keys())\n",
    "for _iter in range(len(train_data)):\n",
    "    for _elem in train_data_l[_iter].split(' '):\n",
    "        feature_matrix[_iter][map_vocab_to_idx.get(_elem)] = 1\n",
    "        \n",
    "if False:\n",
    "    np.set_printoptions(threshold=sys.maxsize)\n",
    "    print(feature_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience-venv",
   "language": "python",
   "name": "datascience-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
